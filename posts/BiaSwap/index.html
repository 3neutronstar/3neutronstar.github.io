<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)" /><meta name="author" content="Minsoo Kang" /><meta property="og:locale" content="en" /><meta name="description" content="이번에는 ICCV 2021에 accept 된 Kaist의 BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation 리뷰하려고 합니다. 자세한 내용은 원문을 참고해주세요." /><meta property="og:description" content="이번에는 ICCV 2021에 accept 된 Kaist의 BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation 리뷰하려고 합니다. 자세한 내용은 원문을 참고해주세요." /><link rel="canonical" href="https://3neutronstar.github.io/posts/BiaSwap/" /><meta property="og:url" content="https://3neutronstar.github.io/posts/BiaSwap/" /><meta property="og:site_name" content="Minsoo Kang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-26T00:34:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)" /><meta name="google-site-verification" content="U178vNNc3QWDKyqjEqpo6Pr-R65h_NlTrflAdNLIees" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Minsoo Kang"},"dateModified":"2022-09-12T18:14:08+09:00","datePublished":"2022-07-26T00:34:00+09:00","description":"이번에는 ICCV 2021에 accept 된 Kaist의 BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation 리뷰하려고 합니다. 자세한 내용은 원문을 참고해주세요.","headline":"(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)","mainEntityOfPage":{"@type":"WebPage","@id":"https://3neutronstar.github.io/posts/BiaSwap/"},"url":"https://3neutronstar.github.io/posts/BiaSwap/"}</script><title>(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021) | Minsoo Kang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Minsoo Kang"><meta name="application-name" content="Minsoo Kang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/examples.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Minsoo Kang</a></div><div class="site-subtitle font-italic">M.S student in Korea University, and Research student in KIST.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/3neutronstar" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['minsoo.kang','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1658763240" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 26, 2022 </em> </span> <span> Updated <em class="" data-ts="1662974048" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Sep 12, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> Minsoo Kang </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2134 words"> <em>11 min</em> read</span></div></div></div><div class="post-content"><p>이번에는 ICCV 2021에 accept 된 Kaist의 BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation 리뷰하려고 합니다. 자세한 내용은 <a href="https://arxiv.org/pdf/2108.10008">원문</a>을 참고해주세요.</p><p>Deep neural network는 보통 dataset에 존재하는 spurious correlation에 기반해서 prediction을 하는 경우가 많다고 합니다. 쉽게 말하면 ground truth라고 알고있는 대상을 보지 않고 correlated된 다른 feature를 기반으로 하는 경우가 많다는 것이죠.</p><p>이러한 것은 unbiased data distribution환경에서 generalization에 실패하는 경우도 많았기에 이러한 문제를 다뤘던 기존의 approach들이 있었다고 합니다. 흔히 생각해볼 수 있는 것은 pre-defined된 bias attribute를 통해서 하는 경우도 있지만, 이러한 것은 사실 비용도 비싸고 어려울 것이라는 추측은 간단하게 해볼 수 있을 것입니다.</p><p>그렇기에 최근 논문에서는 bias attribute를 unsupervised debiasing을 목표로 하는 방식을 취했습니다. 해당 방법에서는 unbiased 뿐만 아니라 biased sample에 대해서 classification ability를 유지하는 방향으로 update하는 것이 굉장히 중요했습니다.</p><p>본 논문에서는 explicit한 supervision없이 dataset bias를 하는 것과 bias-guiding sample과 bias-contrary sample 모두에서 좋은 성능을 보여주는데에 집중했다고 합니다.</p><p>여기서 bias-guiding sample은 bias가 존재하는 sample로서 새라면 뒤의 배경 하늘 정도가 되겠고, bias-contrary sample에서 object가 새라면 뒤의 배경이 용암일 확률이 적으니 그런 sample이라고 볼 수 있습니다.</p><p>본 논문에서 제안하는 BiaSwap은 translation 기반의 augmentation framework로서 각 이미지에서 나타나는 부분들을 다른 이미지로 transfer하여 추론 시키는 방식입니다. Bias가 easy-to-learn attribute로 구성되어있는 점에서 기인하여, bias attribute를 다른 exemplar image에 옮기는 방법이라고 할 수 있습니다. 그러면 bias-guiding sample을 bias-contrary로 옮겨서 debiasing을 한다 라고 생각하시면 좋을 것 같네요.</p><p>옮기는 위치는 Bias-relevant region의 CAM에서 빠르게 학습되어 나타나기 때문에 bias type을 정의하지 않고도 옮길 수 있다고 합니다.</p><h4 id="preliminary"><span class="mr-2"><strong>Preliminary</strong></span><a href="#preliminary" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>$z_b$: bias-guiding attribute</p><p>$z_{-b}$: bias-contrary attribute</p><p>$z_{g}$: essential attribute</p><p>BiaSwap은 $z_g$를 보는 능력을 유지하면서 $z_b$를 $z_{-b}$로 transfer를 하는 것을 목표로 하는 것이라고 생각하시면 됩니다.</p><h4 id="debiasing-approaches-by-removing-bias-with-prior-knowledge"><span class="mr-2"><strong>Debiasing approaches by removing bias with prior knowledge</strong></span><a href="#debiasing-approaches-by-removing-bias-with-prior-knowledge" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>기존 방법은 prior knowledge를 기반으로 AdaIN을 통한 style transfer-based augmentation method를 제안했는데, 해당 부분은 texture bias에 대해 robust하게 만들어주는 방법을 이었습니다.</p><h4 id="debiasing-approaches-by-removing-bias-without-explicit-supervision"><span class="mr-2"><strong>Debiasing approaches by removing bias without explicit supervision</strong></span><a href="#debiasing-approaches-by-removing-bias-without-explicit-supervision" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Supervision이 없는 경우에는 adversarial perturbation을 latent space에 부여해서 image를 synthesizing한 효과를 갖도록 하였습니다. 또한, early training phase에서는 bias 가 easy-to-learn한 성질을 가지고 있어서 generalized-CrossEntropy <a href="https://3neutronstar.github.io/posts/Learning-Debiased/">참조</a>를 통해서 biased train network를 조절된 weight로 학습하도록 하는 것이었다.</p><p>본 논문에서는 truely debiased classifier가 존재한다면 $z_g$를 잘 학습하는데, 이전 방법들은 biased dataset에 대해서는 심각한 performance degradation을 겪고 있다는 사실을 확인했고, 이는 bias-guiding attribute 자체를 피해가는 것이 문제일 것이라는 가정을 했다고 합니다.</p><p>그래서 본 논문에서는 bias-tailored (bias를 참조하는) augmentation을 사용해서 효과적으로 bias를 제거하고, generalized debiasing capability를 달성할 수 있을 것으로 기대한다고 합니다.</p><h3 id="biaswap"><span class="mr-2"><strong>BiaSwap</strong></span><a href="#biaswap" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Bias-guiding and bias-contraray group로 training sample을 효과적으로 나누는 method를 제안했습니다. Explicit한 supervision없이 image에 대해서 bias label을 pseudo-labeling을 진행합니다. bias는 easy-to-learn이고, bias-contrary는 hard-to-learn임을 생각해보면 pseudo-labeling을 통해서 bias-guiding 인지 bias-contrary인지 confidence와 correctness를 관찰함으로써 구분이 가능합니다.</p><p>Binary category를 구별하기 위해 $f_{bias}$인 biased classifier를 Generalized Cross-Entropy (GCE)로 학습시킵니다. <a href="https://3neutronstar.github.io/posts/Learning-Debiased/">참조</a> Noise robust하다는 특성을 고려하여 gCE는 biased representation을 amplify를 할 수 있게 되는데, 그것은 ground truth 확률 $p_y$에 의해 결정되게 됩니다. (GCE gradient식을 참조하시면 좋습니다.)</p><p>GCE loss의 역할은 학습이 쉬운 sample에 더 많은 importance를 부여하여 GCE로의 biased classifier의 학습이 가속화되게 하는 역할을 합니다.</p><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image1.png" alt="image1" data-proofer-ignore></p><p>그러고, 위 식처럼 각 sample의 bias score를 얻을 수 있는데, bias가 많이 되어있을 수록 score가 낮아지는 형태로 계산을 합니다. 위 식으로 부터 bias인지 아닌지를 binary하게 나타낼 수 있고 이를 다음과 같은 pseudo bias label $~y_{bias}$로 얻을 수 있으며, 해당하는 기준은 여러 sample읠 평균을 바탕으로 그 위는 unbiased, 아래는 biased로 구분합니다.</p><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image2.png" alt="image2" data-proofer-ignore></p><h4 id="bias-tailored-swapping-autoencoder"><span class="mr-2"><strong>Bias-tailored swapping autoencoder</strong></span><a href="#bias-tailored-swapping-autoencoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>주어진 pair에 대해서 image-to-image translation method인 Swap AE를 사용해서 bias-contrary sample로 bias-aligned sample을 translation하는 방법을 제안합니다.</p><p>기존 SwapAE와 달리 bias-aware attributes를 translate하기 위해서 patch cooccurrence discriminator를 바꿔서 Bias-tailored patch discriminator를 제안합니다.</p><h5 id="swapping-autoencoder"><span class="mr-2"><strong>Swapping Autoencoder</strong></span><a href="#swapping-autoencoder" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image3.jpg" alt="image3" data-proofer-ignore></p><p>Swap AE는 Auto encoder의 기본적인 구조를 따르는데 encoding 된 latent vector가 style vector $z_s$와 content feature $z_c$로 구성이 되며, AE의 reconstruction loss와 생성된 이미지의 adversarial loss를 활용합니다. 여기서 $D$는 discriminaotr이다. \(L_{recon}(E,G)=\textit{E}_{x\sim\chi}[||x-G(E(x))||^2_2]\) \(L_{GAN,recon}(E,G,D)=E_{x\sim\chi}[-logD(G(E(x)))]\)</p><p>SwapAE는 여기서 stlye을 translate을 하기 위해서 한 이미지 $x_1$의 latent vector중 $z_s^1$을 $z_c^2$와 결합하여 Generator에 넘겨서 학습하는 형태를 사용합니다. 여기서 Patch co-occurrence discriminaotr $D_{patch}$가 style을 정확하게 random sample된 patch로부터 만들어내도록 합니다. 이를 정리하면 아래의 식처럼 $x^{2}$로 부터 여러개의 patch를 crop한 것들과 $x^1$과 $x^2$의 latent끼리 합쳐진 tuple로 부터 생성된 이미지를 배우게 되어 아래의 식처럼 objective가 구성되게 됩니다.</p><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image4.jpg" alt="image4" data-proofer-ignore></p><p>이 때, image를 더 realistic하게 만들기 위해서 SwapAE 논문에서는 $x^1$과 $x^2$가 같지 않게 GAN의 adversarial loss가 되도록 구성했습니다.</p><h5 id="cam-based-patch-sampling"><span class="mr-2"><strong>CAM-based patch sampling</strong></span><a href="#cam-based-patch-sampling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p>기존 논문에서는 $D_{patch}$에 ramdom하게 sample된 patch가 들어가게 되어있는데, 이는 biased sample의 입장에서 certain attribute에 상관 없이 style이 들어가게 된다는 사실을 알 수 있습니다. 그런 점에서 corresponding한 style을 추출시킬 필요가 있었습니다. Bias classifier인 $f_{bias}$를 활용해서 CAM방식으로 spatial region의 어떤 부분이 classify되는지를 활용합니다. Bias classifier이기 때문에 각 class에 대한 activation point를 확인할 수 있을 것이라 생각했습니다. logit for class $c$는 다음과 같이 나타낼 수 있게 되고 importance를 다음의 식으로 나타낼 수 있습니다. \(I_c(x,y)=\sum_{x,y}{\sum_{k}{w^c_k f_{bias,k}(x,y)}}\)</p><p>이 때, $f_{bias,k}(x,y)$는 흔히 아는 global average pooled actiation map이다. 이렇게 되면 biased classifier에 대해서 large value인 $I_c$가 각 location이 bias attributes를 얼마나 가지고 있는지를 나타낼 수 있게 됩니다. Sampling probability로 만들기 위해서 본 논문에서는 값을 softmax를 취하게 됩니다. 본 값을 가지고 sample된 patch를 Discriminator와 Generator에 활용하고 bias-tailored patch discriminator의 objective는 아래식으로 구성됩니다.</p><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image5.jpg" alt="image5" data-proofer-ignore></p><p>이렇게 생성된 이미지는 original image와 같이 섞여져 reasonable한 sample을 만들어낸 후, 적절한 비율을 사용하여 $f_{debias}$ classifier를 classification loss로 training하게 됩니다.</p><h3 id="experiments"><span class="mr-2"><strong>Experiments</strong></span><a href="#experiments" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image6.jpg" alt="image6" data-proofer-ignore></p><p>다시 상기시키자면, 본 논문의 목적은 bias guiding과 bias contrary sample 모두 잘하는 것을 목적으로 합니다. 결과적으로 unbiased sample에 대해서는 잘해지기는 했지만, 논문에서 제안한 만큼 unbiased를 잘 풀어내는 것 같지는 않았습니다. (Corrupted cifar10 0.5%에서 29%는 사실 아쉽기는 한 것 같습니다.)</p><p>그래도 real world에 대해서는 제법 잘한다는 사실을 알 수 있습니다. (bFFHQ는 0.5% / BAR dataset)</p><p><img data-src="/assets/paper_review/2022-09-05-BiaSwap/image7.jpg" alt="image7" data-proofer-ignore></p><p>더 자세한 내용은 본문을 참조해주세요.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>Paper Review</a>, <a href='/categories/debiasing/'>Debiasing</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/iccv-2021/" class="post-tag no-text-decoration" >ICCV 2021</a> <a href="/tags/paper-review/" class="post-tag no-text-decoration" >Paper Review</a> <a href="/tags/debiasing/" class="post-tag no-text-decoration" >Debiasing</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%28Paper+Review%29+BiaSwap%3A+Removing+Dataset+Bias+with+Bias-Tailored+Swapping+Augmentation+%28ICCV+2021%29+-+Minsoo+Kang&url=https%3A%2F%2F3neutronstar.github.io%2Fposts%2FBiaSwap%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%28Paper+Review%29+BiaSwap%3A+Removing+Dataset+Bias+with+Bias-Tailored+Swapping+Augmentation+%28ICCV+2021%29+-+Minsoo+Kang&u=https%3A%2F%2F3neutronstar.github.io%2Fposts%2FBiaSwap%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2F3neutronstar.github.io%2Fposts%2FBiaSwap%2F&text=%28Paper+Review%29+BiaSwap%3A+Removing+Dataset+Bias+with+Bias-Tailored+Swapping+Augmentation+%28ICCV+2021%29+-+Minsoo+Kang" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/GuidedMixup/">(Paper Review) GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps (AAAI 2023)</a><li><a href="/posts/Learning-Debiased/">(Paper Review) Learning Debiased Representation via Disentangled Feature Augmentation (NeurIPS 2021)</a><li><a href="/posts/BiaSwap/">(Paper Review) BiaSwap: Removing Dataset Bias with Bias-Tailored Swapping Augmentation (ICCV 2021)</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/paper-review/">Paper Review</a> <a class="post-tag" href="/tags/debiasing/">Debiasing</a> <a class="post-tag" href="/tags/aaai-2023/">AAAI 2023</a> <a class="post-tag" href="/tags/aaai/">AAAI</a> <a class="post-tag" href="/tags/data-augmentation/">Data Augmentation</a> <a class="post-tag" href="/tags/guidedmixup/">GuidedMixup</a> <a class="post-tag" href="/tags/iccv-2021/">ICCV 2021</a> <a class="post-tag" href="/tags/mixup-based-augmentation/">Mixup-based Augmentation</a> <a class="post-tag" href="/tags/mixup/">Mixup</a> <a class="post-tag" href="/tags/neurips-2021/">NeurIPS 2021</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Learning-Debiased/"><div class="card-body"> <em class="small" data-ts="1658763240" data-df="ll" > Jul 26, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Paper Review) Learning Debiased Representation via Disentangled Feature Augmentation (NeurIPS 2021)</h3><div class="text-muted small"><p> 이번에는 NeurIPS 2021에 accept 된 Kaist와 Kakao의 Learning Debiased Representation via Disentangled Feature Augmentation 리뷰하려고 합니다. 자세한 내용은 원문을 참고해주세요.  최근의 Deep Neural Network는 주변 속성들을 기반으로 decision을 진행하...</p></div></div></a></div><div class="card"> <a href="/posts/GuidedMixup/"><div class="card-body"> <em class="small" data-ts="1669130340" data-df="ll" > Nov 23, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Paper Review) GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps (AAAI 2023)</h3><div class="text-muted small"><p> &amp;lt;/br&amp;gt;</p></div></div></a></div><div class="card"> <a href="/posts/About/"><div class="card-body"> <em class="small" data-ts="1641006000" data-df="ll" > Jan 1, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>About</h3><div class="text-muted small"><p> Hello, this is my new website instead of Tistory. You can check my personal information on the About page.</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Learning-Debiased/" class="btn btn-outline-primary" prompt="Older"><p>(Paper Review) Learning Debiased Representation via Disentangled Feature Augmentation (NeurIPS 2021)</p></a> <a href="/posts/GuidedMixup/" class="btn btn-outline-primary" prompt="Newer"><p>(Paper Review) GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps (AAAI 2023)</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/3neutronstar">Minsoo Kang</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/paper-review/">Paper Review</a> <a class="post-tag" href="/tags/debiasing/">Debiasing</a> <a class="post-tag" href="/tags/aaai-2023/">AAAI 2023</a> <a class="post-tag" href="/tags/aaai/">AAAI</a> <a class="post-tag" href="/tags/data-augmentation/">Data Augmentation</a> <a class="post-tag" href="/tags/guidedmixup/">GuidedMixup</a> <a class="post-tag" href="/tags/iccv-2021/">ICCV 2021</a> <a class="post-tag" href="/tags/mixup-based-augmentation/">Mixup-based Augmentation</a> <a class="post-tag" href="/tags/mixup/">Mixup</a> <a class="post-tag" href="/tags/neurips-2021/">NeurIPS 2021</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
